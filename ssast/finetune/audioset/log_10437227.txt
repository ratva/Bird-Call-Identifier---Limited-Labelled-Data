+ source /cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/activate
++ _CONDA_ROOT=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406
++ . /cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/etc/profile.d/conda.sh
+++ export CONDA_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda
+++ CONDA_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python
+++ CONDA_PYTHON_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python
+++ '[' -z x ']'
++ conda activate
++ local cmd=activate
++ case "$cmd" in
++ __conda_activate activate
++ '[' -n '' ']'
++ local ask_conda
+++ PS1=
+++ __conda_exe shell.posix activate
+++ /cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda shell.posix activate
++ ask_conda='PS1='\''(base) '\''
export PATH='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/condabin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/home/ashen05/.local/bin:/cluster/home/ashen05/bin:/cluster/home/ashen05/.vscode-server/cli/servers/Stable-138f619c86f1199955d53b4166bef66ef252935c/server/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin'\''
export CONDA_PREFIX='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_1='\''/cluster/home/ashen05/.conda/envs/myenv'\''
export CONDA_EXE='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python'\''
. "/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/etc/conda/activate.d/libglib_activate.sh"'
++ eval 'PS1='\''(base) '\''
export PATH='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/condabin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/home/ashen05/.local/bin:/cluster/home/ashen05/bin:/cluster/home/ashen05/.vscode-server/cli/servers/Stable-138f619c86f1199955d53b4166bef66ef252935c/server/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin'\''
export CONDA_PREFIX='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406'\''
export CONDA_SHLVL='\''2'\''
export CONDA_DEFAULT_ENV='\''base'\''
export CONDA_PROMPT_MODIFIER='\''(base) '\''
export CONDA_PREFIX_1='\''/cluster/home/ashen05/.conda/envs/myenv'\''
export CONDA_EXE='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda'\''
export _CE_M='\'''\''
export _CE_CONDA='\'''\''
export CONDA_PYTHON_EXE='\''/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python'\''
. "/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/etc/conda/activate.d/libglib_activate.sh"'
+++ PS1='(base) '
+++ export PATH=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/condabin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/home/ashen05/.local/bin:/cluster/home/ashen05/bin:/cluster/home/ashen05/.vscode-server/cli/servers/Stable-138f619c86f1199955d53b4166bef66ef252935c/server/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
+++ PATH=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/condabin:/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin:/cluster/home/ashen05/.local/bin:/cluster/home/ashen05/bin:/cluster/home/ashen05/.vscode-server/cli/servers/Stable-138f619c86f1199955d53b4166bef66ef252935c/server/bin/remote-cli:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
+++ export CONDA_PREFIX=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406
+++ CONDA_PREFIX=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406
+++ export CONDA_SHLVL=2
+++ CONDA_SHLVL=2
+++ export CONDA_DEFAULT_ENV=base
+++ CONDA_DEFAULT_ENV=base
+++ export 'CONDA_PROMPT_MODIFIER=(base) '
+++ CONDA_PROMPT_MODIFIER='(base) '
+++ export CONDA_PREFIX_1=/cluster/home/ashen05/.conda/envs/myenv
+++ CONDA_PREFIX_1=/cluster/home/ashen05/.conda/envs/myenv
+++ export CONDA_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda
+++ CONDA_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/conda
+++ export _CE_M=
+++ _CE_M=
+++ export _CE_CONDA=
+++ _CE_CONDA=
+++ export CONDA_PYTHON_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python
+++ CONDA_PYTHON_EXE=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/bin/python
+++ . /cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/etc/conda/activate.d/libglib_activate.sh
++++ export GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ GSETTINGS_SCHEMA_DIR_CONDA_BACKUP=
++++ export GSETTINGS_SCHEMA_DIR=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/share/glib-2.0/schemas
++++ GSETTINGS_SCHEMA_DIR=/cluster/tufts/hpc/apps/rhel8/external/apps/anaconda/202406/share/glib-2.0/schemas
++ __conda_hashr
++ '[' -n '' ']'
++ '[' -n '' ']'
++ hash -r
+ export TORCH_HOME=../../pretrained_models
+ TORCH_HOME=../../pretrained_models
+ mkdir -p ./exp
+ '[' -e SSAST-Base-Patch-400.pth ']'
+ echo 'pretrained model already downloaded.'
pretrained model already downloaded.
+ pretrain_exp=
+ pretrain_model=SSAST-Base-Patch-400
+ pretrain_path=.//SSAST-Base-Patch-400.pth
+ dataset=birdclef
+ set=balanced
+ dataset_mean=-4.2677393
+ dataset_std=4.5689974
+ target_length=1024
+ noise=False
+ task=ft_avgtok
+ model_size=base
+ head_lr=1
+ warmup=True
+ last_layer_finetuning=True
+ lr_decay=0.5
+ '[' balanced == balanced ']'
+ bal=none
+ lr=5e-4
+ epoch=50
+ tr_data=/cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/train_audio.json
+ te_data=/cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/test_audio.json
+ va_data=/cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/val_audio.json
+ freqm=48
+ timem=192
+ mixup=0.5
+ fstride=10
+ tstride=10
+ fshape=16
+ tshape=16
+ batch_size=12
+ exp_dir=./exp/SSAST-50epochs-lr5e-4-lastlayerftTrue-decay0.5
+ class_indices=/cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/data/birdclef_class_labels.csv
+ CUDA_CACHE_DISABLE=1
+ python -W ignore ../../run.py --dataset birdclef --data-train /cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/train_audio.json --data-val /cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/val_audio.json --data-eval /cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/Data/test_audio.json --exp-dir ./exp/SSAST-50epochs-lr5e-4-lastlayerftTrue-decay0.5 --label-csv /cluster/tufts/cs152l3dclass/ashen05/ssast/src/finetune/audioset/data/birdclef_class_labels.csv --n_class 12 --lr 5e-4 --n-epochs 50 --batch-size 12 --save_model False --freqm 48 --timem 192 --mixup 0.5 --bal none --tstride 10 --fstride 10 --fshape 16 --tshape 16 --warmup False --task ft_avgtok --model_size base --adaptschedule False --pretrained_mdl_path .//SSAST-Base-Patch-400.pth --dataset_mean -4.2677393 --dataset_std 4.5689974 --target_length 1024 --num_mel_bins 128 --head_lr 1 --noise False --lrscheduler_start 10 --lrscheduler_step 5 --lrscheduler_decay 0.5 --wa True --wa_start 6 --wa_end 25 --loss BCE --metrics mAP --last_layer_ft True
2024-12-13 21:00:17.490463: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-12-13 21:00:17.505731: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1734141617.524043  219485 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1734141617.529508  219485 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-12-13 21:00:17.549918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
I am process 219485, running on p1cmp077.pax.tufts.edu: starting (Fri Dec 13 21:00:23 2024)
balanced sampler is not used
---------------the train dataloader---------------
now using following mask: 48 freq, 192 time
now using mix-up with rate 0.500000
now process birdclef
now skip normalization (use it ONLY when you are computing the normalization stats).
number of classes is 12
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process birdclef
now skip normalization (use it ONLY when you are computing the normalization stats).
number of classes is 12
Now train with birdclef with 1432 training samples, evaluate with 410 samples
now load a SSL pretrained models from .//SSAST-Base-Patch-400.pth
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212

Creating experiment directory: ./exp/SSAST-50epochs-lr5e-4-lastlayerftTrue-decay0.5
Now starting fine-tuning for 50 epochs
Summary writer initialized
running on cuda
Total parameter number is : 87.736 million
Total trainable parameter number is : 0.011 million
The mlp header uses 1 x larger lr
Total mlp parameter number is : 0.011 million
Total base parameter number is : 87.725 million
now training with birdclef, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x2ae396979d30>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2024-12-13 21:00:24.871825
current #epochs=1, #steps=0
Epoch: [1][100/119]	Per Sample Total Time 0.29443	Per Sample Data Time 0.25713	Per Sample DNN Time 0.03730	Train Loss 0.3088	
start validation
mAP: 0.143881
AUC: 0.603812
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.372260
train_loss: 0.304031
valid_loss: 0.731626
validation finished
normal learning rate scheduler step
Epoch-1 lr: 0.0005
epoch 1 training time: 492.139
---------------
2024-12-13 21:08:37.011224
current #epochs=2, #steps=119
Epoch: [2][81/119]	Per Sample Total Time 0.30059	Per Sample Data Time 0.26329	Per Sample DNN Time 0.03730	Train Loss 0.2801	
start validation
mAP: 0.154899
AUC: 0.630154
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.469887
train_loss: 0.281313
valid_loss: 0.730360
validation finished
normal learning rate scheduler step
Epoch-2 lr: 0.0005
epoch 2 training time: 470.696
---------------
2024-12-13 21:16:27.707037
current #epochs=3, #steps=238
Epoch: [3][62/119]	Per Sample Total Time 0.25973	Per Sample Data Time 0.22233	Per Sample DNN Time 0.03740	Train Loss 0.2798	
start validation
mAP: 0.168953
AUC: 0.648782
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.540279
train_loss: 0.278871
valid_loss: 0.729121
validation finished
normal learning rate scheduler step
Epoch-3 lr: 0.0005
epoch 3 training time: 486.566
---------------
2024-12-13 21:24:34.273129
current #epochs=4, #steps=357
Epoch: [4][43/119]	Per Sample Total Time 0.22994	Per Sample Data Time 0.19263	Per Sample DNN Time 0.03731	Train Loss 0.2784	
start validation
mAP: 0.178575
AUC: 0.666515
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.608551
train_loss: 0.278011
valid_loss: 0.727890
validation finished
normal learning rate scheduler step
Epoch-4 lr: 0.0005
epoch 4 training time: 491.343
---------------
2024-12-13 21:32:45.616826
current #epochs=5, #steps=476
Epoch: [5][24/119]	Per Sample Total Time 0.32826	Per Sample Data Time 0.29080	Per Sample DNN Time 0.03746	Train Loss 0.2762	
start validation
mAP: 0.193395
AUC: 0.684356
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.678703
train_loss: 0.277398
valid_loss: 0.727657
validation finished
normal learning rate scheduler step
Epoch-5 lr: 0.0005
epoch 5 training time: 497.199
---------------
2024-12-13 21:41:02.815216
current #epochs=6, #steps=595
Epoch: [6][5/119]	Per Sample Total Time 0.53358	Per Sample Data Time 0.49583	Per Sample DNN Time 0.03775	Train Loss 0.2793	
Epoch: [6][105/119]	Per Sample Total Time 0.31051	Per Sample Data Time 0.27316	Per Sample DNN Time 0.03735	Train Loss 0.2772	
start validation
mAP: 0.202251
AUC: 0.691993
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.709241
train_loss: 0.276181
valid_loss: 0.728167
validation finished
normal learning rate scheduler step
Epoch-6 lr: 0.0005
epoch 6 training time: 512.777
---------------
2024-12-13 21:49:35.592634
current #epochs=7, #steps=714
Epoch: [7][86/119]	Per Sample Total Time 0.28729	Per Sample Data Time 0.24985	Per Sample DNN Time 0.03744	Train Loss 0.2765	
start validation
mAP: 0.209423
AUC: 0.695744
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.724358
train_loss: 0.276464
valid_loss: 0.729441
validation finished
normal learning rate scheduler step
Epoch-7 lr: 0.0005
epoch 7 training time: 481.761
---------------
2024-12-13 21:57:37.353702
current #epochs=8, #steps=833
Epoch: [8][67/119]	Per Sample Total Time 0.24388	Per Sample Data Time 0.20648	Per Sample DNN Time 0.03740	Train Loss 0.2742	
start validation
mAP: 0.221816
AUC: 0.713295
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.796255
train_loss: 0.274040
valid_loss: 0.728594
validation finished
normal learning rate scheduler step
Epoch-8 lr: 0.0005
epoch 8 training time: 477.276
---------------
2024-12-13 22:05:34.629373
current #epochs=9, #steps=952
Epoch: [9][48/119]	Per Sample Total Time 0.28628	Per Sample Data Time 0.24890	Per Sample DNN Time 0.03738	Train Loss 0.2761	
start validation
mAP: 0.222435
AUC: 0.717060
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.811944
train_loss: 0.274254
valid_loss: 0.728108
validation finished
normal learning rate scheduler step
Epoch-9 lr: 0.0005
epoch 9 training time: 482.049
---------------
2024-12-13 22:13:36.677915
current #epochs=10, #steps=1071
Epoch: [10][29/119]	Per Sample Total Time 0.26555	Per Sample Data Time 0.22805	Per Sample DNN Time 0.03750	Train Loss 0.2777	
start validation
mAP: 0.226430
AUC: 0.720964
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.828317
train_loss: 0.274460
valid_loss: 0.729407
validation finished
normal learning rate scheduler step
Epoch-10 lr: 0.00025
epoch 10 training time: 484.371
---------------
2024-12-13 22:21:41.048766
current #epochs=11, #steps=1190
Epoch: [11][10/119]	Per Sample Total Time 0.21702	Per Sample Data Time 0.17985	Per Sample DNN Time 0.03717	Train Loss 0.2717	
Epoch: [11][110/119]	Per Sample Total Time 0.28187	Per Sample Data Time 0.24444	Per Sample DNN Time 0.03744	Train Loss 0.2722	
start validation
mAP: 0.238550
AUC: 0.726261
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.850713
train_loss: 0.271668
valid_loss: 0.727891
validation finished
normal learning rate scheduler step
Epoch-11 lr: 0.00025
epoch 11 training time: 480.548
---------------
2024-12-13 22:29:41.596484
current #epochs=12, #steps=1309
Epoch: [12][91/119]	Per Sample Total Time 0.27141	Per Sample Data Time 0.23388	Per Sample DNN Time 0.03753	Train Loss 0.2706	
start validation
mAP: 0.241456
AUC: 0.729358
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.863904
train_loss: 0.270686
valid_loss: 0.728099
validation finished
normal learning rate scheduler step
Epoch-12 lr: 0.00025
epoch 12 training time: 488.668
---------------
2024-12-13 22:37:50.264671
current #epochs=13, #steps=1428
Epoch: [13][72/119]	Per Sample Total Time 0.26663	Per Sample Data Time 0.22902	Per Sample DNN Time 0.03761	Train Loss 0.2735	
start validation
mAP: 0.250678
AUC: 0.734601
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.886411
train_loss: 0.272425
valid_loss: 0.726830
validation finished
normal learning rate scheduler step
Epoch-13 lr: 0.00025
epoch 13 training time: 487.687
---------------
2024-12-13 22:45:57.951813
current #epochs=14, #steps=1547
Epoch: [14][53/119]	Per Sample Total Time 0.29480	Per Sample Data Time 0.25729	Per Sample DNN Time 0.03751	Train Loss 0.2693	
start validation
mAP: 0.248602
AUC: 0.735318
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.889507
train_loss: 0.269826
valid_loss: 0.728371
validation finished
normal learning rate scheduler step
Epoch-14 lr: 0.00025
epoch 14 training time: 474.549
---------------
2024-12-13 22:53:52.500616
current #epochs=15, #steps=1666
Epoch: [15][34/119]	Per Sample Total Time 0.36174	Per Sample Data Time 0.32450	Per Sample DNN Time 0.03724	Train Loss 0.2706	
start validation
mAP: 0.248829
AUC: 0.736863
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.896192
train_loss: 0.269500
valid_loss: 0.727459
validation finished
normal learning rate scheduler step
Epoch-15 lr: 0.000125
epoch 15 training time: 480.347
---------------
2024-12-13 23:01:52.848102
current #epochs=16, #steps=1785
Epoch: [16][15/119]	Per Sample Total Time 0.41024	Per Sample Data Time 0.37271	Per Sample DNN Time 0.03753	Train Loss 0.2676	
Epoch: [16][115/119]	Per Sample Total Time 0.28745	Per Sample Data Time 0.25001	Per Sample DNN Time 0.03744	Train Loss 0.2694	
start validation
mAP: 0.253553
AUC: 0.741154
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.914866
train_loss: 0.269710
valid_loss: 0.726721
validation finished
normal learning rate scheduler step
Epoch-16 lr: 0.000125
epoch 16 training time: 482.769
---------------
2024-12-13 23:09:55.617251
current #epochs=17, #steps=1904
Epoch: [17][96/119]	Per Sample Total Time 0.25705	Per Sample Data Time 0.21965	Per Sample DNN Time 0.03740	Train Loss 0.2691	
start validation
mAP: 0.251609
AUC: 0.739570
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.907955
train_loss: 0.269746
valid_loss: 0.727039
validation finished
normal learning rate scheduler step
Epoch-17 lr: 0.000125
epoch 17 training time: 482.557
---------------
2024-12-13 23:17:58.174842
current #epochs=18, #steps=2023
Epoch: [18][77/119]	Per Sample Total Time 0.32191	Per Sample Data Time 0.28442	Per Sample DNN Time 0.03749	Train Loss 0.2677	
start validation
mAP: 0.253523
AUC: 0.741183
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.914992
train_loss: 0.268165
valid_loss: 0.726901
validation finished
normal learning rate scheduler step
Epoch-18 lr: 0.000125
epoch 18 training time: 466.864
---------------
2024-12-13 23:25:45.037959
current #epochs=19, #steps=2142
Epoch: [19][58/119]	Per Sample Total Time 0.28762	Per Sample Data Time 0.25025	Per Sample DNN Time 0.03737	Train Loss 0.2696	
start validation
mAP: 0.257754
AUC: 0.743630
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.925713
train_loss: 0.268180
valid_loss: 0.727166
validation finished
normal learning rate scheduler step
Epoch-19 lr: 0.000125
epoch 19 training time: 480.673
---------------
2024-12-13 23:33:45.711209
current #epochs=20, #steps=2261
Epoch: [20][39/119]	Per Sample Total Time 0.28775	Per Sample Data Time 0.25014	Per Sample DNN Time 0.03761	Train Loss 0.2662	
start validation
mAP: 0.258675
AUC: 0.745454
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.933739
train_loss: 0.267935
valid_loss: 0.726614
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-05
epoch 20 training time: 477.799
---------------
2024-12-13 23:41:43.510159
current #epochs=21, #steps=2380
Epoch: [21][20/119]	Per Sample Total Time 0.29973	Per Sample Data Time 0.26222	Per Sample DNN Time 0.03751	Train Loss 0.2698	
start validation
mAP: 0.261748
AUC: 0.747678
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.943564
train_loss: 0.268683
valid_loss: 0.727242
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-05
epoch 21 training time: 479.807
---------------
2024-12-13 23:49:43.317276
current #epochs=22, #steps=2499
Epoch: [22][1/119]	Per Sample Total Time 0.21905	Per Sample Data Time 0.18185	Per Sample DNN Time 0.03721	Train Loss 0.2726	
Epoch: [22][101/119]	Per Sample Total Time 0.27721	Per Sample Data Time 0.23969	Per Sample DNN Time 0.03752	Train Loss 0.2686	
start validation
mAP: 0.261129
AUC: 0.747215
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.941516
train_loss: 0.268095
valid_loss: 0.726634
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-05
epoch 22 training time: 485.982
---------------
2024-12-13 23:57:49.298955
current #epochs=23, #steps=2618
Epoch: [23][82/119]	Per Sample Total Time 0.29343	Per Sample Data Time 0.25611	Per Sample DNN Time 0.03732	Train Loss 0.2669	
start validation
mAP: 0.262002
AUC: 0.747571
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.943088
train_loss: 0.267218
valid_loss: 0.726800
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-05
epoch 23 training time: 475.086
---------------
2024-12-14 00:05:44.385241
current #epochs=24, #steps=2737
Epoch: [24][63/119]	Per Sample Total Time 0.32430	Per Sample Data Time 0.28684	Per Sample DNN Time 0.03745	Train Loss 0.2685	
start validation
mAP: 0.261665
AUC: 0.747392
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.942296
train_loss: 0.269033
valid_loss: 0.726651
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-05
epoch 24 training time: 477.409
---------------
2024-12-14 00:13:41.793748
current #epochs=25, #steps=2856
Epoch: [25][44/119]	Per Sample Total Time 0.27641	Per Sample Data Time 0.23890	Per Sample DNN Time 0.03750	Train Loss 0.2674	
start validation
mAP: 0.262559
AUC: 0.748051
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.945216
train_loss: 0.267066
valid_loss: 0.726736
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-05
epoch 25 training time: 482.356
---------------
2024-12-14 00:21:44.150292
current #epochs=26, #steps=2975
Epoch: [26][25/119]	Per Sample Total Time 0.31885	Per Sample Data Time 0.28142	Per Sample DNN Time 0.03744	Train Loss 0.2687	
start validation
mAP: 0.263341
AUC: 0.748577
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.947550
train_loss: 0.267662
valid_loss: 0.726634
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.125e-05
epoch 26 training time: 479.835
---------------
2024-12-14 00:29:43.984599
current #epochs=27, #steps=3094
Epoch: [27][6/119]	Per Sample Total Time 0.27935	Per Sample Data Time 0.24192	Per Sample DNN Time 0.03743	Train Loss 0.2643	
Epoch: [27][106/119]	Per Sample Total Time 0.28302	Per Sample Data Time 0.24563	Per Sample DNN Time 0.03739	Train Loss 0.2669	
start validation
mAP: 0.264439
AUC: 0.749392
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.951167
train_loss: 0.266904
valid_loss: 0.726762
validation finished
normal learning rate scheduler step
Epoch-27 lr: 3.125e-05
epoch 27 training time: 498.021
---------------
2024-12-14 00:38:02.006015
current #epochs=28, #steps=3213
Epoch: [28][87/119]	Per Sample Total Time 0.30181	Per Sample Data Time 0.26452	Per Sample DNN Time 0.03729	Train Loss 0.2671	
start validation
mAP: 0.264294
AUC: 0.749275
Avg Precision: 0.083333
Avg Recall: 1.000000
d_prime: 0.950647
train_loss: 0.267247
valid_loss: 0.726769
validation finished
normal learning rate scheduler step
Epoch-28 lr: 3.125e-05
epoch 28 training time: 478.051
Stopped early at epoch 29
---------------evaluate on the validation set---------------
Accuracy: 0.234146
AUC: 0.749392
---------------the evaluation dataloader---------------
now using following mask: 0 freq, 0 time
now using mix-up with rate 0.000000
now process birdclef
now skip normalization (use it ONLY when you are computing the normalization stats).
number of classes is 12
---------------evaluate on the test set---------------
Accuracy: 0.248780
AUC: 0.700017
